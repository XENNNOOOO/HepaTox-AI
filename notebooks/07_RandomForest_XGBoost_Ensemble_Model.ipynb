{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c7582a9",
   "metadata": {},
   "source": [
    "## Notebook 8: Random Forest Classifier x XGBoost Ensemble Model\n",
    "\n",
    "Create the highest-performing model by ensembling our two best classifiers: the tuned RandomForest and the tuned XGBoost model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d8c15",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c19fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import ast \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61637c5",
   "metadata": {},
   "source": [
    "###  Load the Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dacaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('data/processed/dili_data_clean.csv')\n",
    "    print(\"Processed data loaded successfully.\")\n",
    "    print(f\"Shape of the dataset: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: dili_data_clean.csv not found.\")\n",
    "    print(\"Please make sure you have uploaded the file to your Colab session.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b392b23d",
   "metadata": {},
   "source": [
    "### Prepare the Data for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d621413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing fingerprints\n",
    "df.dropna(subset=['fingerprint'], inplace=True)\n",
    "print(f\"Shape after dropping NaNs: {df.shape}\")\n",
    "\n",
    "# Safely convert the string representation of the list back into a list of integers\n",
    "df['fingerprint'] = df['fingerprint'].apply(ast.literal_eval)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = np.array(df['fingerprint'].tolist())\n",
    "y = df['dili_concern'].values\n",
    "\n",
    "# Create a train/test split for final evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nData prepared for modeling:\")\n",
    "print(f\" - Training features shape: {X_train.shape}\")\n",
    "print(f\" - Testing features shape:  {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fa920c",
   "metadata": {},
   "source": [
    "### Train the Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235a0309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Tuned RandomForest Model\n",
    "print(\"Training the tuned RandomForest model...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"RandomForest training complete.\")\n",
    "\n",
    "# Train the Tuned XGBoost Model \n",
    "# Best parameters found by Optuna\n",
    "best_xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'use_label_encoder': False,\n",
    "    'random_state': 42,\n",
    "    'n_estimators': 349,\n",
    "    'max_depth': 9,\n",
    "    'learning_rate': 0.013094879048120515,\n",
    "    'subsample': 0.7701118471150662,\n",
    "    'colsample_bytree': 0.8656908580435939,\n",
    "    'gamma': 0.03486754343407765,\n",
    "    'min_child_weight': 1\n",
    "}\n",
    "\n",
    "# Add class weight balancing\n",
    "neg_count = np.sum(y_train == 0)\n",
    "pos_count = np.sum(y_train == 1)\n",
    "best_xgb_params['scale_pos_weight'] = neg_count / pos_count if pos_count > 0 else 1\n",
    "\n",
    "print(\"\\nTraining the tuned XGBoost model...\")\n",
    "xgb_model = xgb.XGBClassifier(**best_xgb_params)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"XGBoost training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2736724b",
   "metadata": {},
   "source": [
    "### Create and Evaluate the Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d37362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted probabilities from both models on the test set\n",
    "print(\"\\nGenerating predictions from individual models...\")\n",
    "rf_probs = rf_model.predict_proba(X_test)[:, 1]\n",
    "xgb_probs = xgb_model.predict_proba(X_test)[:, 1]\n",
    "print(f\" - RandomForest probabilities shape: {rf_probs.shape}\")\n",
    "print(f\" - XGBoost probabilities shape:      {xgb_probs.shape}\")\n",
    "\n",
    "# Simple Averaging Ensemble\n",
    "# Combine the predictions by taking their average\n",
    "ensemble_probs = (rf_probs + xgb_probs) / 2.0\n",
    "print(f\"\\nEnsemble probabilities calculated. Shape: {ensemble_probs.shape}\")\n",
    "\n",
    "# Convert probabilities to final 0/1 predictions\n",
    "ensemble_preds = (ensemble_probs > 0.5).astype(int)\n",
    "\n",
    "# Calculate Final Metrics\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_preds)\n",
    "ensemble_roc_auc = roc_auc_score(y_test, ensemble_probs) # Use probabilities for ROC AUC\n",
    "\n",
    "print(\"\\n--- Final Ensemble Model Performance ---\")\n",
    "print(f\"Accuracy on Test Set: {ensemble_accuracy:.3f}\")\n",
    "print(f\"ROC AUC on Test Set:  {ensemble_roc_auc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9290ac4",
   "metadata": {},
   "source": [
    "### Visualize Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7546992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix for the Ensemble Model\n",
    "cm = confusion_matrix(y_test, ensemble_preds)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No DILI Concern', 'DILI Concern'],\n",
    "            yticklabels=['No DILI Concern', 'DILI Concern'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix for Final Ensemble Model')\n",
    "plt.show()\n",
    "\n",
    "# ROC AUC Comparison Chart\n",
    "# Get the individual model performances for a fair comparison\n",
    "rf_test_roc_auc = roc_auc_score(y_test, rf_probs)\n",
    "xgb_test_roc_auc = roc_auc_score(y_test, xgb_probs)\n",
    "\n",
    "model_names = ['RandomForest', 'Tuned XGBoost', 'Ensemble']\n",
    "roc_auc_scores = [rf_test_roc_auc, xgb_test_roc_auc, ensemble_roc_auc]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(model_names, roc_auc_scores, color=['#4299E1', '#48BB78', '#ED8936'])\n",
    "plt.ylabel('ROC AUC Score')\n",
    "plt.title('Final Model Performance Comparison')\n",
    "plt.ylim(0.7, 0.82) # Zoom in on the relevant score range\n",
    "plt.axhline(y=0.81, color='r', linestyle='--', label='Target (81%)')\n",
    "plt.legend()\n",
    "\n",
    "# Add score labels on top of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.3f}', va='bottom', ha='center')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52216e0",
   "metadata": {},
   "source": [
    "### Final Comparison and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd88ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Final Model Comparison ---\")\n",
    "print(\"Metric         | RandomForest | Tuned XGBoost | Ensemble Model\")\n",
    "print(\"----------------|--------------|---------------|----------------\")\n",
    "print(f\"ROC AUC       | {rf_test_roc_auc:.3f}        | {xgb_test_roc_auc:.3f}         | {ensemble_roc_auc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
