{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48f06a71",
   "metadata": {},
   "source": [
    "## Notebook 11: Training on the HepaTox Dataset\n",
    "\n",
    "Training XGBoost model on the large-scale HepaTox dataset. This represents our best and final attempt to surpass the 81% performance target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb9544",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd6ef85",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.notebook import tqdm\n",
    "import ast\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, AllChem\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebec76c",
   "metadata": {},
   "source": [
    "### Load the InterDILI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623f1c4a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('Total_dataset.csv')\n",
    "    print(\"HepaTox dataset loaded successfully.\")\n",
    "    print(f\"Shape of the dataset: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Total_dataset.csv not found.\")\n",
    "    print(\"Please make sure you have uploaded the file to your Colab session.\")\n",
    "\n",
    "# Initial Data Cleaning\n",
    "df.rename(columns={'toxicity': 'dili_concern'}, inplace=True)\n",
    "# Drop rows with missing SMILES strings\n",
    "df.dropna(subset=['smiles'], inplace=True)\n",
    "print(f\"Shape after dropping NaNs: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b4c812",
   "metadata": {},
   "source": [
    "### Engineer a Comprehensive Feature Set\n",
    "Generate both the Morgan fingerprints and the 28 physicochemical descriptors for this new, larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf697b5c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Generate Morgan Fingerprints\n",
    "def generate_fingerprint(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        return list(AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024))\n",
    "    return None\n",
    "\n",
    "print(\"Generating Morgan Fingerprints...\")\n",
    "tqdm.pandas(desc=\"Fingerprinting\")\n",
    "df['fingerprint'] = df['smiles'].progress_apply(generate_fingerprint)\n",
    "\n",
    "# Generate Physicochemical Descriptors\n",
    "def calculate_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return [np.nan] * 28\n",
    "    \n",
    "    return [\n",
    "        Descriptors.MolWt(mol), Descriptors.MolLogP(mol), Descriptors.TPSA(mol),\n",
    "        Descriptors.NumHAcceptors(mol), Descriptors.NumHDonors(mol), Descriptors.NumRotatableBonds(mol),\n",
    "        Descriptors.NOCount(mol), Descriptors.NumAliphaticCarbocycles(mol),\n",
    "        Descriptors.NumAliphaticHeterocycles(mol), Descriptors.NumAliphaticRings(mol),\n",
    "        Descriptors.NumAromaticCarbocycles(mol), Descriptors.NumAromaticHeterocycles(mol),\n",
    "        Descriptors.NumAromaticRings(mol), Descriptors.NumSaturatedCarbocycles(mol),\n",
    "        Descriptors.NumSaturatedHeterocycles(mol), Descriptors.NumSaturatedRings(mol),\n",
    "        Descriptors.RingCount(mol), Descriptors.MolMR(mol), Descriptors.FractionCSP3(mol),\n",
    "        Descriptors.HeavyAtomCount(mol), Descriptors.NHOHCount(mol), Descriptors.NOCount(mol),\n",
    "        Descriptors.NumAliphaticRings(mol), Descriptors.NumAromaticRings(mol),\n",
    "        Descriptors.NumHAcceptors(mol), Descriptors.NumHDonors(mol),\n",
    "        Descriptors.NumHeteroatoms(mol), Descriptors.NumRotatableBonds(mol)\n",
    "    ]\n",
    "\n",
    "descriptor_names = [\n",
    "    'MolWt', 'MolLogP', 'TPSA', 'NumHAcceptors', 'NumHDonors', 'NumRotatableBonds',\n",
    "    'NOCount', 'NumAliphaticCarbocycles', 'NumAliphaticHeterocycles', 'NumAliphaticRings',\n",
    "    'NumAromaticCarbocycles', 'NumAromaticHeterocycles', 'NumAromaticRings',\n",
    "    'NumSaturatedCarbocycles', 'NumSaturatedHeterocycles', 'NumSaturatedRings', 'RingCount',\n",
    "    'MolMR', 'FractionCSP3', 'HeavyAtomCount', 'NHOHCount', 'LipinskiNOCount',\n",
    "    'LipinskiNumAliphaticRings', 'LipinskiNumAromaticRings', 'LipinskiNumHAcceptors',\n",
    "    'LipinskiNumHDonors', 'NumHeteroatoms', 'LipinskiNumRotatableBonds'\n",
    "]\n",
    "\n",
    "print(\"\\nCalculating 28 physicochemical descriptors...\")\n",
    "tqdm.pandas(desc=\"Calculating Descriptors\")\n",
    "descriptor_features = df['smiles'].progress_apply(lambda s: pd.Series(calculate_descriptors(s)))\n",
    "descriptor_features.columns = descriptor_names\n",
    "\n",
    "df = pd.concat([df.reset_index(drop=True), descriptor_features.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Final cleanup\n",
    "df.dropna(inplace=True)\n",
    "print(f\"\\nFeature generation complete. Final dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d244da58",
   "metadata": {},
   "source": [
    "### Final Hybrid Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf82121",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fingerprints = np.array(df['fingerprint'].tolist())\n",
    "descriptors = df[descriptor_names].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "descriptors_scaled = scaler.fit_transform(descriptors)\n",
    "\n",
    "X_hybrid = np.concatenate([fingerprints, descriptors_scaled], axis=1)\n",
    "y = df['dili_concern'].values\n",
    "\n",
    "print(f\"Shape of final hybrid features: {X_hybrid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438858d5",
   "metadata": {},
   "source": [
    "### Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fed6ad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_hybrid, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Best XGBoost parameters\n",
    "best_xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'use_label_encoder': False,\n",
    "    'random_state': 42,\n",
    "    'n_estimators': 349,\n",
    "    'max_depth': 9,\n",
    "    'learning_rate': 0.013094879048120515,\n",
    "    'subsample': 0.7701118471150662,\n",
    "    'colsample_bytree': 0.8656908580435939,\n",
    "    'gamma': 0.03486754343407765,\n",
    "    'min_child_weight': 1\n",
    "}\n",
    "\n",
    "# Class weight balancing\n",
    "neg_count = np.sum(y_train == 0)\n",
    "pos_count = np.sum(y_train == 1)\n",
    "best_xgb_params['scale_pos_weight'] = neg_count / pos_count if pos_count > 0 else 1\n",
    "\n",
    "print(\"\\nTraining the final XGBoost model on the HepaTox dataset...\")\n",
    "final_model = xgb.XGBClassifier(**best_xgb_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "print(\"Final model training complete.\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = final_model.predict(X_test)\n",
    "y_pred_proba = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate final metrics\n",
    "final_accuracy = accuracy_score(y_test, y_pred)\n",
    "final_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Save the Model\n",
    "MODEL_OUTPUT_DIR = 'models'\n",
    "MODEL_PATH = os.path.join(MODEL_OUTPUT_DIR, 'XGBoost22k_model.pkl')\n",
    "\n",
    "os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "joblib.dump(final_model, MODEL_PATH)\n",
    "print(f\"\\nChampion model successfully saved to '{MODEL_PATH}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d05ad9",
   "metadata": {},
   "source": [
    "### Results and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd783e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- XGBoost Model Performance ---\")\n",
    "print(f\"Accuracy on Test Set: {final_accuracy:.3f}\")\n",
    "print(f\"ROC AUC on Test Set:  {final_roc_auc:.3f}\")\n",
    "\n",
    "print(\"\\n--- Comparison ---\")\n",
    "print(\"Metric         | Previous Best (Ensemble) | HepaTox-Trained Model\")\n",
    "print(\"----------------|--------------------------|-----------------------\")\n",
    "ensemble_roc_auc = 0.768 \n",
    "print(f\"ROC AUC       | {ensemble_roc_auc:.3f}                     | {final_roc_auc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
