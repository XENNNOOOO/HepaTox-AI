{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51152e70",
   "metadata": {},
   "source": [
    "## Notebook 6: Deeper GIN Model\n",
    "\n",
    "Improve upon our previous GIN model by increasing its depth. By adding more layers, we give the model the capacity to learn more complex relationships and potentially increase its predictive power.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752807a2",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dac873e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU, BatchNorm1d\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# RDKit for chemoinformatics\n",
    "from rdkit import Chem\n",
    "\n",
    "# PyTorch Geometric\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GINConv, global_add_pool\n",
    "\n",
    "# Scikit-learn for evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c6265",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6cbc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data loaded successfully.\n",
      "Converting SMILES to graph objects...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33049744071b4b8cb0a59e2910261f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/907 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:15:13] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:13] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:13] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:14] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:14] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:14] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:14] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:14] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:15] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:15] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:15] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:15] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:16] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:16] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:16] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:16] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:16] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:16] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:16] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:17] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:17] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:17] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:17] WARNING: not removing hydrogen atom without neighbors\n",
      "[23:15:17] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final aligned dataset size: 907\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('data/processed/dili_data_clean.csv')\n",
    "    df.dropna(subset=['fingerprint', 'smiles'], inplace=True)\n",
    "    print(\"Processed data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: dili_data_clean.csv not found.\")\n",
    "\n",
    "# Graph Data Conversion\n",
    "def get_atom_features(atom):\n",
    "    features = [atom.GetAtomicNum(), atom.GetDegree(), atom.GetFormalCharge(), int(atom.GetHybridization()), atom.GetIsAromatic()]\n",
    "    return features\n",
    "\n",
    "def smiles_to_graph(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None: return None\n",
    "    atom_features = [get_atom_features(atom) for atom in mol.GetAtoms()]\n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n",
    "    if mol.GetNumBonds() > 0:\n",
    "        edge_indices = []\n",
    "        for bond in mol.GetBonds():\n",
    "            i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "            edge_indices.extend([(i, j), (j, i)])\n",
    "        edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "print(\"Converting SMILES to graph objects...\")\n",
    "data_list = [smiles_to_graph(s) for s in tqdm(df['smiles'])]\n",
    "\n",
    "successful_indices = [i for i, d in enumerate(data_list) if d is not None]\n",
    "data_list = [data_list[i] for i in successful_indices]\n",
    "y = df['dili_concern'].iloc[successful_indices].values\n",
    "\n",
    "for i, data in enumerate(data_list):\n",
    "    data.y = torch.tensor([y[i]], dtype=torch.float)\n",
    "\n",
    "print(f\"Final aligned dataset size: {len(data_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb9fefd",
   "metadata": {},
   "source": [
    "### Create Train and Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26d5e95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test splits created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(len(data_list))\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "train_data = [data_list[i] for i in train_indices]\n",
    "test_data = [data_list[i] for i in test_indices]\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"Train/test splits created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c2e52",
   "metadata": {},
   "source": [
    "### Define the Deeper GIN Model\n",
    "\n",
    "Increased the model's depth from 2 to 4 GIN layers. We also add Batch Normalization, which helps stabilize training for deeper networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "539b1145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deeper GIN Model defined:\n",
      "DeeperGIN(\n",
      "  (conv1): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=5, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  ))\n",
      "  (conv2): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  ))\n",
      "  (conv3): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  ))\n",
      "  (conv4): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  ))\n",
      "  (lin): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_node_features = data_list[0].x.shape[1]\n",
    "\n",
    "class DeeperGIN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(DeeperGIN, self).__init__()\n",
    "        \n",
    "        # Layer 1\n",
    "        mlp1 = Sequential(Linear(num_node_features, hidden_channels), BatchNorm1d(hidden_channels), ReLU(), Linear(hidden_channels, hidden_channels))\n",
    "        self.conv1 = GINConv(mlp1)\n",
    "        \n",
    "        # Layer 2\n",
    "        mlp2 = Sequential(Linear(hidden_channels, hidden_channels), BatchNorm1d(hidden_channels), ReLU(), Linear(hidden_channels, hidden_channels))\n",
    "        self.conv2 = GINConv(mlp2)\n",
    "        \n",
    "        # Layer 3\n",
    "        mlp3 = Sequential(Linear(hidden_channels, hidden_channels), BatchNorm1d(hidden_channels), ReLU(), Linear(hidden_channels, hidden_channels))\n",
    "        self.conv3 = GINConv(mlp3)\n",
    "        \n",
    "        # Layer 4\n",
    "        mlp4 = Sequential(Linear(hidden_channels, hidden_channels), BatchNorm1d(hidden_channels), ReLU(), Linear(hidden_channels, hidden_channels))\n",
    "        self.conv4 = GINConv(mlp4)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = self.conv4(x, edge_index).relu()\n",
    "        \n",
    "        x = global_add_pool(x, batch)\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "model = DeeperGIN(hidden_channels=64)\n",
    "print(\"Deeper GIN Model defined:\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80bcb19",
   "metadata": {},
   "source": [
    "### Train the Deeper Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6152ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Deeper GIN training...\n",
      "Epoch: 10, Loss: 0.3130\n",
      "Epoch: 20, Loss: 0.2773\n",
      "Epoch: 30, Loss: 0.2369\n",
      "Epoch: 40, Loss: 0.2063\n",
      "Epoch: 50, Loss: 0.1771\n",
      "Epoch: 60, Loss: 0.1566\n",
      "Epoch: 70, Loss: 0.1233\n",
      "Epoch: 80, Loss: 0.1136\n",
      "Epoch: 90, Loss: 0.1060\n",
      "Epoch: 100, Loss: 0.0974\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "neg_count = np.sum(y[train_indices] == 0)\n",
    "pos_count = np.sum(y[train_indices] == 1)\n",
    "pos_weight_value = neg_count / pos_count if pos_count > 0 else 1\n",
    "pos_weight_tensor = torch.tensor([pos_weight_value], dtype=torch.float)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out, data.y.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "print(\"Starting Deeper GIN training...\")\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    scheduler.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
    "print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c394a3",
   "metadata": {},
   "source": [
    "### Evaluate the Deeper Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29cd8af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            probs = torch.sigmoid(out).view(-1)\n",
    "            all_probs.extend(probs.tolist())\n",
    "            all_labels.extend(data.y.view(-1).tolist())\n",
    "    return np.array(all_probs), np.array(all_labels)\n",
    "\n",
    "y_probs, y_true = test(test_loader)\n",
    "y_pred = (y_probs > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "deep_gin_accuracy = accuracy_score(y_true, y_pred)\n",
    "deep_gin_roc_auc = roc_auc_score(y_true, y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6454cdd",
   "metadata": {},
   "source": [
    "### Compare Results and Conclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9aa164b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Deeper GIN Model Performance ---\n",
      "Accuracy: 0.742\n",
      "ROC AUC:  0.739\n",
      "\n",
      "--- Comparison ---\n",
      "Metric         | RandomForest (Baseline) | Deeper GIN Model\n",
      "----------------|-------------------------|------------------\n",
      "ROC AUC       | 0.761                   | 0.739\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Deeper GIN Model Performance ---\")\n",
    "print(f\"Accuracy: {deep_gin_accuracy:.3f}\")\n",
    "print(f\"ROC AUC:  {deep_gin_roc_auc:.3f}\")\n",
    "\n",
    "print(\"\\n--- Comparison ---\")\n",
    "print(\"Metric         | RandomForest (Baseline) | Deeper GIN Model\")\n",
    "print(\"----------------|-------------------------|------------------\")\n",
    "rf_roc_auc = 0.761 # From our previous best model\n",
    "print(f\"ROC AUC       | {rf_roc_auc:.3f}                   | {deep_gin_roc_auc:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
