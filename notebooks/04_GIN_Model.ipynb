{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04385164",
   "metadata": {},
   "source": [
    "## Notebook 4: GIN Model\n",
    "\n",
    "Implement, train, and evaluate a Graph Isomorphism Network (GIN), a powerful and robust GNN architecture. Our aim is to surpass the RandomForest baseline and achieve an ROC AUC score greater than 0.81.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a451f036",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92639985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# RDKit for chemoinformatics\n",
    "from rdkit import Chem\n",
    "\n",
    "# PyTorch Geometric\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GINConv, global_add_pool\n",
    "\n",
    "# Scikit-learn for evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e5677e",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0d9d600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data loaded successfully.\n",
      "Converting SMILES to graph objects...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68313bf08d8a42068cdfd7bb02eb5112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/907 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:44:10] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:11] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:11] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:11] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:11] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:11] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:12] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:12] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:12] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:12] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:13] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:13] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:13] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:13] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:13] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:13] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:13] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:14] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:14] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:14] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:14] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:14] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:14] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:44:14] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created 907 graph objects.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('data/processed/dili_data_clean.csv')\n",
    "    df.dropna(subset=['fingerprint', 'smiles'], inplace=True)\n",
    "    print(\"Processed data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: dili_data_clean.csv not found.\")\n",
    "\n",
    "# --- Graph Conversion Functions ---\n",
    "def get_atom_features(atom):\n",
    "    features = []\n",
    "    features.append(atom.GetAtomicNum())\n",
    "    features.append(atom.GetDegree())\n",
    "    features.append(atom.GetFormalCharge())\n",
    "    features.append(int(atom.GetHybridization()))\n",
    "    features.append(atom.GetIsAromatic())\n",
    "    return features\n",
    "\n",
    "def smiles_to_graph(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None: return None\n",
    "    \n",
    "    atom_features = [get_atom_features(atom) for atom in mol.GetAtoms()]\n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n",
    "\n",
    "    if mol.GetNumBonds() > 0:\n",
    "        edge_indices = []\n",
    "        for bond in mol.GetBonds():\n",
    "            i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "            edge_indices.extend([(i, j), (j, i)])\n",
    "        edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# --- Create Graph Dataset ---\n",
    "print(\"Converting SMILES to graph objects...\")\n",
    "data_list = [smiles_to_graph(s) for s in tqdm(df['smiles'])]\n",
    "\n",
    "successful_indices = [i for i, d in enumerate(data_list) if d is not None]\n",
    "data_list = [data_list[i] for i in successful_indices]\n",
    "labels = df['dili_concern'].iloc[successful_indices].values\n",
    "\n",
    "for i, data in enumerate(data_list):\n",
    "    data.y = torch.tensor([labels[i]], dtype=torch.float)\n",
    "\n",
    "print(f\"Successfully created {len(data_list)} graph objects.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c25039",
   "metadata": {},
   "source": [
    "### Create Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b344d9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 725\n",
      "Number of testing graphs: 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(data_list, test_size=0.2, random_state=42, stratify=labels)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Number of training graphs: {len(train_data)}\")\n",
    "print(f\"Number of testing graphs: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e028857f",
   "metadata": {},
   "source": [
    "### Define the GIN Model\n",
    "\n",
    "Define a GIN with a simple Multi-Layer Perceptron (MLP) as its internal network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bb37aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIN Model defined:\n",
      "GIN(\n",
      "  (conv1): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=5, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  ))\n",
      "  (conv2): GINConv(nn=Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  ))\n",
      "  (lin): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_node_features = data_list[0].x.shape[1]\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GIN, self).__init__()\n",
    "        \n",
    "        # Define the MLP for the GIN convolution\n",
    "        mlp1 = Sequential(Linear(num_node_features, hidden_channels), ReLU(), Linear(hidden_channels, hidden_channels))\n",
    "        self.conv1 = GINConv(mlp1)\n",
    "        \n",
    "        mlp2 = Sequential(Linear(hidden_channels, hidden_channels), ReLU(), Linear(hidden_channels, hidden_channels))\n",
    "        self.conv2 = GINConv(mlp2)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        \n",
    "        # Use global add pooling to get a graph-level representation\n",
    "        x = global_add_pool(x, batch)\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "model = GIN(hidden_channels=64)\n",
    "print(\"GIN Model defined:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e4789b",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6a00c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GIN training...\n",
      "Epoch: 10, Loss: 0.4788\n",
      "Epoch: 20, Loss: 0.3629\n",
      "Epoch: 30, Loss: 0.3597\n",
      "Epoch: 40, Loss: 0.3495\n",
      "Epoch: 50, Loss: 0.3449\n",
      "Epoch: 60, Loss: 0.3490\n",
      "Epoch: 70, Loss: 0.3402\n",
      "Epoch: 80, Loss: 0.3398\n",
      "Epoch: 90, Loss: 0.3355\n",
      "Epoch: 100, Loss: 0.3344\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "# Calculate class weights\n",
    "neg_count = np.sum(labels == 0)\n",
    "pos_count = np.sum(labels == 1)\n",
    "pos_weight_value = neg_count / pos_count if pos_count > 0 else 1\n",
    "pos_weight_tensor = torch.tensor([pos_weight_value], dtype=torch.float)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out, data.y.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "print(\"Starting GIN training...\")\n",
    "for epoch in range(1, 101): # Train for 100 epochs\n",
    "    loss = train()\n",
    "    scheduler.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815afe22",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "244f5c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            preds = (torch.sigmoid(out) > 0.5).float()\n",
    "            all_preds.extend(preds.view(-1).tolist())\n",
    "            all_labels.extend(data.y.view(-1).tolist())\n",
    "    return np.array(all_preds), np.array(all_labels)\n",
    "\n",
    "y_pred, y_true = test(test_loader)\n",
    "\n",
    "# Calculate metrics\n",
    "gin_accuracy = accuracy_score(y_true, y_pred)\n",
    "gin_roc_auc = roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d5098c",
   "metadata": {},
   "source": [
    "### Compare Results and Conclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28ec2dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GIN Model Performance ---\n",
      "Accuracy: 0.648\n",
      "ROC AUC:  0.605\n",
      "\n",
      "--- Comparison ---\n",
      "Metric         | RandomForest (Baseline) | GIN Model\n",
      "----------------|-------------------------|-----------\n",
      "ROC AUC       | 0.761                   | 0.605\n"
     ]
    }
   ],
   "source": [
    "print(\"--- GIN Model Performance ---\")\n",
    "print(f\"Accuracy: {gin_accuracy:.3f}\")\n",
    "print(f\"ROC AUC:  {gin_roc_auc:.3f}\")\n",
    "\n",
    "print(\"\\n--- Comparison ---\")\n",
    "print(\"Metric         | RandomForest (Baseline) | GIN Model\")\n",
    "print(\"----------------|-------------------------|-----------\")\n",
    "rf_roc_auc = 0.761\n",
    "print(f\"ROC AUC       | {rf_roc_auc:.3f}                   | {gin_roc_auc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
